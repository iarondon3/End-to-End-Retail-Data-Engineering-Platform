{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMI395XkAUEIHgknxs3dRXs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iarondon3/End-to-End-Retail-Data-Ecosystem/blob/main/02-Distributed-Architecture/distributed_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# âš™ï¸ Step 1: Scenario Configuration"
      ],
      "metadata": {
        "id": "O2AnRrKtvoAf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wG-6CtCGvJ9g"
      },
      "outputs": [],
      "source": [
        "# @markdown Select the transaction volume for the Distributed Lab.\n",
        "\n",
        "# @markdown We will shard data by **State** (10 US States).\n",
        "\n",
        "SALES_VOLUME = 30000  # @param {type:\"slider\", min:10000, max:100000, step:10000}\n",
        "\n",
        "print(f\"ðŸŽ¯ Configuration: Will generate {SALES_VOLUME} transactions across 10 States.\")\n",
        "print(\"   Click 'Play' on the next cell to install Citus (PostgreSQL Distributed).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **ðŸ” What just happened?**\n",
        "\n",
        "> We defined the **Scope of the Simulation**. By setting the `SALES_VOLUME`, you determined the load that our synthetic generator will produce. This variable is stored globally and will be used by the scripts in the next steps to ensure the volume is consistent with your stress-test goals."
      ],
      "metadata": {
        "id": "GNgZ16vP78ch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ—ï¸ Step 2: Install & Start Citus Engine *(Click Play)*"
      ],
      "metadata": {
        "id": "m7Mvd4TJvcvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "#\n",
        "import os\n",
        "import time\n",
        "import subprocess\n",
        "\n",
        "start_time = time.time()\n",
        "print(\"ðŸ“¦ Installing Citus Data extension (this takes ~60s)...\")\n",
        "\n",
        "# 1. Instalar Repositorios y Paquetes\n",
        "os.system(\"curl https://install.citusdata.com/community/deb.sh | sudo bash > /dev/null 2>&1\")\n",
        "os.system(\"sudo apt-get -y -q install postgresql-16-citus-12.1 > /dev/null 2>&1\")\n",
        "os.system(\"pip install psycopg2-binary faker jupysql > /dev/null 2>&1\")\n",
        "\n",
        "# 2. Inicializar Cluster de Base de Datos\n",
        "print(\"ðŸš€ Initializing Distributed Cluster...\")\n",
        "os.system(\"sudo service postgresql stop\")\n",
        "\n",
        "# Inicializamos el directorio de datos\n",
        "cmd_init = \"sudo -u postgres /usr/lib/postgresql/16/bin/pg_ctl -D /etc/postgresql/16/main initdb -o '-A trust'\"\n",
        "subprocess.run(cmd_init, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "# 3. --- APLICAR PARCHE DE SEGURIDAD (TRUST) ---\n",
        "# Esto evita el error 'fe_sendauth: no password supplied'\n",
        "print(\"ðŸ” Applying Security Patch (Trust Mode)...\")\n",
        "pg_hba_content = \"\"\"\n",
        "# TYPE  DATABASE        USER            ADDRESS                 METHOD\n",
        "local   all             all                                     trust\n",
        "host    all             all             127.0.0.1/32            trust\n",
        "host    all             all             ::1/128                 trust\n",
        "\"\"\"\n",
        "os.system(f\"sudo sh -c 'echo \\\"{pg_hba_content}\\\" > /etc/postgresql/16/main/pg_hba.conf'\")\n",
        "\n",
        "# Configurar librerÃ­as de Citus\n",
        "os.system(\"echo \\\"shared_preload_libraries = 'citus'\\\" | sudo tee -a /etc/postgresql/16/main/postgresql.conf > /dev/null\")\n",
        "\n",
        "# 4. Iniciar Servicio\n",
        "print(\"ðŸ”„ Starting Service...\")\n",
        "os.system(\"sudo service postgresql start\")\n",
        "\n",
        "# 5. Crear Base de Datos y ExtensiÃ³n\n",
        "print(\"ðŸ”Œ Enabling Citus Extension...\")\n",
        "os.system('sudo -u postgres psql -c \"CREATE EXTENSION citus;\"')\n",
        "os.system('sudo -u postgres psql -c \"CREATE DATABASE walgreens_distributed;\"')\n",
        "os.system('sudo -u postgres psql -d walgreens_distributed -c \"CREATE EXTENSION citus;\"')\n",
        "\n",
        "elapsed = round(time.time() - start_time, 2)\n",
        "print(f\"âœ… Citus Environment Ready & Patched in {elapsed} seconds!\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "baH4_Yz-vdFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **ðŸ” What just happened?**\n",
        "\n",
        "> Since Google Colab is a transient environment, we had to provision the infrastructure from scratch.\n",
        "> 1. We installed **PostgreSQL 16** and the **Citus 12.1** extension.\n",
        "> 2. We initialized the database cluster.\n",
        "> 3. **Crucial Step:** We applied a security patch to `pg_hba.conf` (Trust Mode). This allows the Citus Coordinator to communicate with its internal Worker nodes (logical shards) without authentication errors, overcoming the \"password supplied\" issue."
      ],
      "metadata": {
        "id": "1uSwH3Gr8HR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ—ï¸ Step 3: Populate Data - Full Distributed Architecture *(Click Play)*"
      ],
      "metadata": {
        "id": "18In10UCxNf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "#\n",
        "import psycopg2\n",
        "import psycopg2.extras\n",
        "from faker import Faker\n",
        "import random\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "TARGET_STATES = [\"CA\", \"PA\", \"FL\", \"TX\", \"IL\", \"NC\", \"OH\", \"GA\", \"NY\", \"MI\"]\n",
        "try:\n",
        "    TOTAL_SALES = SALES_VOLUME\n",
        "except NameError:\n",
        "    TOTAL_SALES = 10000\n",
        "\n",
        "DB_CONFIG = {\n",
        "    'dbname': 'walgreens_distributed',\n",
        "    'user': 'postgres',\n",
        "    'password': 'postgres',\n",
        "    'host': 'localhost',\n",
        "    'port': '5432'\n",
        "}\n",
        "\n",
        "print(f\"ðŸŽ² Generating Full Schema (13 Tables) for {len(TARGET_STATES)} States...\")\n",
        "fake = Faker('en_US')\n",
        "conn = psycopg2.connect(**DB_CONFIG)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# --- 1. DDL: SCHEMA DEFINITION FOR SHARDING ---\n",
        "# CRITICAL FIX: We do NOT drop the schema (to save Citus extension).\n",
        "# We only drop the tables we are about to create.\n",
        "cursor.execute(\"\"\"\n",
        "    DROP TABLE IF EXISTS\n",
        "        Sale_Detail, Sale, Invoice_Detail, Invoice, Redeemed_Coupon, Points_Movement,\n",
        "        Employee, Customer, Branch, Product, Coupon, Payment_Method, Category\n",
        "    CASCADE;\n",
        "\"\"\")\n",
        "\n",
        "cursor.execute(\"\"\"\n",
        "-- === TYPE A: REFERENCE TABLES (Will be Replicated) ===\n",
        "CREATE TABLE Category (category_id SERIAL PRIMARY KEY, name VARCHAR(100));\n",
        "CREATE TABLE Payment_Method (payment_id SERIAL PRIMARY KEY, name VARCHAR(50));\n",
        "CREATE TABLE Coupon (coupon_id SERIAL PRIMARY KEY, code VARCHAR(50), discount_pct INT);\n",
        "CREATE TABLE Product (product_id SERIAL PRIMARY KEY, category_id INT, name VARCHAR(150), price DECIMAL(10,2));\n",
        "\n",
        "-- === TYPE B: DISTRIBUTED TABLES (Shard Key: state) ===\n",
        "\n",
        "-- 1. Organization\n",
        "CREATE TABLE Branch (\n",
        "    branch_id SERIAL,\n",
        "    state VARCHAR(50),\n",
        "    city VARCHAR(100),\n",
        "    PRIMARY KEY (branch_id, state)\n",
        ");\n",
        "\n",
        "CREATE TABLE Employee (\n",
        "    employee_id SERIAL,\n",
        "    branch_id INT,\n",
        "    state VARCHAR(50), -- Inherited from Branch\n",
        "    first_name VARCHAR(100),\n",
        "    position VARCHAR(100),\n",
        "    PRIMARY KEY (employee_id, state)\n",
        ");\n",
        "\n",
        "-- 2. Customers (Pinned to a home state for sharding)\n",
        "CREATE TABLE Customer (\n",
        "    customer_id SERIAL,\n",
        "    state VARCHAR(50),\n",
        "    first_name VARCHAR(100),\n",
        "    last_name VARCHAR(100),\n",
        "    PRIMARY KEY (customer_id, state)\n",
        ");\n",
        "\n",
        "-- 3. Sales Core\n",
        "CREATE TABLE Sale (\n",
        "    sale_id SERIAL,\n",
        "    branch_id INT,\n",
        "    customer_id INT,\n",
        "    state VARCHAR(50), -- Partition Key\n",
        "    date DATE,\n",
        "    total_amount DECIMAL(10,2),\n",
        "    PRIMARY KEY (sale_id, state)\n",
        ");\n",
        "\n",
        "CREATE TABLE Sale_Detail (\n",
        "    detail_id SERIAL,\n",
        "    sale_id INT,\n",
        "    product_id INT,\n",
        "    state VARCHAR(50), -- Inherited\n",
        "    quantity INT,\n",
        "    subtotal DECIMAL(10,2),\n",
        "    PRIMARY KEY (detail_id, state)\n",
        ");\n",
        "\n",
        "-- 4. Invoicing\n",
        "CREATE TABLE Invoice (\n",
        "    invoice_id SERIAL,\n",
        "    sale_id INT,\n",
        "    state VARCHAR(50), -- Inherited\n",
        "    issued_at TIMESTAMP,\n",
        "    PRIMARY KEY (invoice_id, state)\n",
        ");\n",
        "\n",
        "CREATE TABLE Invoice_Detail (\n",
        "    inv_detail_id SERIAL,\n",
        "    invoice_id INT,\n",
        "    payment_id INT,\n",
        "    state VARCHAR(50), -- Inherited\n",
        "    amount DECIMAL(10,2),\n",
        "    PRIMARY KEY (inv_detail_id, state)\n",
        ");\n",
        "\n",
        "-- 5. Loyalty & Promos\n",
        "CREATE TABLE Redeemed_Coupon (\n",
        "    redemption_id SERIAL,\n",
        "    sale_id INT,\n",
        "    coupon_id INT,\n",
        "    state VARCHAR(50), -- Inherited\n",
        "    PRIMARY KEY (redemption_id, state)\n",
        ");\n",
        "\n",
        "CREATE TABLE Points_Movement (\n",
        "    movement_id SERIAL,\n",
        "    customer_id INT,\n",
        "    state VARCHAR(50), -- Inherited\n",
        "    points INT,\n",
        "    PRIMARY KEY (movement_id, state)\n",
        ");\n",
        "\"\"\")\n",
        "\n",
        "# --- 2. DATA GENERATION HELPERS ---\n",
        "def batch_insert(table, cols, data):\n",
        "    if not data: return\n",
        "    psycopg2.extras.execute_batch(cursor, f\"INSERT INTO {table} ({cols}) VALUES ({'%s,'*(len(data[0])-1)}%s)\", data)\n",
        "\n",
        "# --- 3. POPULATE REFERENCE DATA ---\n",
        "print(\"   ...Populating Reference Tables...\")\n",
        "# Categories\n",
        "batch_insert(\"Category\", \"name\", [(\"Pharmacy\",), (\"Beauty\",), (\"Grocery\",), (\"Electronics\",)])\n",
        "# Payment Methods\n",
        "batch_insert(\"Payment_Method\", \"name\", [(\"Cash\",), (\"Credit Card\",), (\"Debit Card\",), (\"Apple Pay\",)])\n",
        "# Coupons\n",
        "batch_insert(\"Coupon\", \"code, discount_pct\", [(\"SAVE10\", 10), (\"WELCOME20\", 20), (\"SUMMER5\", 5)])\n",
        "# Products\n",
        "prods = []\n",
        "for i in range(1, 101): # 100 products\n",
        "    prods.append((random.randint(1,4), f\"Product {i}\", round(random.uniform(5, 50), 2)))\n",
        "batch_insert(\"Product\", \"category_id, name, price\", prods)\n",
        "\n",
        "# --- 4. POPULATE DISTRIBUTED DATA ---\n",
        "print(\"   ...Populating Distributed Tables (Branches, Employees, Customers)...\")\n",
        "\n",
        "# A. Branches & Employees\n",
        "branches = []\n",
        "employees = []\n",
        "branch_map = {} # id -> state\n",
        "b_id = 1\n",
        "e_id = 1\n",
        "\n",
        "for state in TARGET_STATES:\n",
        "    for _ in range(5): # 5 branches per state\n",
        "        branches.append((b_id, state, fake.city()))\n",
        "        branch_map[b_id] = state\n",
        "\n",
        "        # 4 Employees per branch\n",
        "        for _ in range(4):\n",
        "            employees.append((e_id, b_id, state, fake.first_name(), \"Staff\"))\n",
        "            e_id += 1\n",
        "        b_id += 1\n",
        "\n",
        "batch_insert(\"Branch\", \"branch_id, state, city\", branches)\n",
        "batch_insert(\"Employee\", \"employee_id, branch_id, state, first_name, position\", employees)\n",
        "branch_ids = list(branch_map.keys())\n",
        "\n",
        "# B. Customers (Assign random home state)\n",
        "print(\"   ...Populating Customers...\")\n",
        "customers = []\n",
        "cust_map = {} # id -> state\n",
        "c_id = 1\n",
        "for _ in range(2000):\n",
        "    st = random.choice(TARGET_STATES)\n",
        "    customers.append((c_id, st, fake.first_name(), fake.last_name()))\n",
        "    cust_map[c_id] = st\n",
        "    c_id += 1\n",
        "batch_insert(\"Customer\", \"customer_id, state, first_name, last_name\", customers)\n",
        "cust_ids = list(cust_map.keys())\n",
        "\n",
        "# --- 5. TRANSACTIONAL LOOP (Sales -> Invoice -> Points) ---\n",
        "print(f\"   ...Generating {TOTAL_SALES} Transactions (Complex Hierarchy)...\")\n",
        "\n",
        "sales_batch = []\n",
        "details_batch = []\n",
        "invoice_batch = []\n",
        "inv_det_batch = []\n",
        "points_batch = []\n",
        "\n",
        "s_id = 1\n",
        "inv_id = 1\n",
        "\n",
        "for _ in range(TOTAL_SALES):\n",
        "    # Logic: Pick a branch -> Determine State -> Pick Customer (Ideally local, but simplified)\n",
        "    b_id = random.choice(branch_ids)\n",
        "    state = branch_map[b_id] # CRITICAL: Everything inherits this state\n",
        "\n",
        "    # We pick a random customer. In a real strict shard, customer must match state.\n",
        "    # For simplicity, we just assign the SALE to the BRANCH's state.\n",
        "    c_id = random.choice(cust_ids)\n",
        "\n",
        "    amount = round(random.uniform(20, 150), 2)\n",
        "    date = fake.date_this_year()\n",
        "\n",
        "    # Sale\n",
        "    sales_batch.append((s_id, b_id, c_id, state, date, amount))\n",
        "\n",
        "    # Detail (1 item)\n",
        "    details_batch.append((s_id, 1, state, 1, amount))\n",
        "\n",
        "    # Invoice\n",
        "    invoice_batch.append((inv_id, s_id, state, date))\n",
        "\n",
        "    # Invoice Detail (Payment)\n",
        "    inv_det_batch.append((inv_id, 1, state, amount))\n",
        "\n",
        "    # Points\n",
        "    points_batch.append((c_id, state, 10))\n",
        "\n",
        "    s_id += 1\n",
        "    inv_id += 1\n",
        "\n",
        "    if len(sales_batch) >= 5000:\n",
        "        batch_insert(\"Sale\", \"sale_id, branch_id, customer_id, state, date, total_amount\", sales_batch)\n",
        "        batch_insert(\"Sale_Detail\", \"sale_id, product_id, state, quantity, subtotal\", details_batch)\n",
        "        batch_insert(\"Invoice\", \"invoice_id, sale_id, state, issued_at\", invoice_batch)\n",
        "        batch_insert(\"Invoice_Detail\", \"invoice_id, payment_id, state, amount\", inv_det_batch)\n",
        "        batch_insert(\"Points_Movement\", \"customer_id, state, points\", points_batch)\n",
        "        sales_batch, details_batch, invoice_batch, inv_det_batch, points_batch = [], [], [], [], []\n",
        "\n",
        "# Flush remaining\n",
        "batch_insert(\"Sale\", \"sale_id, branch_id, customer_id, state, date, total_amount\", sales_batch)\n",
        "batch_insert(\"Sale_Detail\", \"sale_id, product_id, state, quantity, subtotal\", details_batch)\n",
        "batch_insert(\"Invoice\", \"invoice_id, sale_id, state, issued_at\", invoice_batch)\n",
        "batch_insert(\"Invoice_Detail\", \"invoice_id, payment_id, state, amount\", inv_det_batch)\n",
        "batch_insert(\"Points_Movement\", \"customer_id, state, points\", points_batch)\n",
        "\n",
        "conn.commit()\n",
        "cursor.close()\n",
        "conn.close()\n",
        "\n",
        "elapsed = round(time.time() - start_time, 2)\n",
        "print(f\"âœ… Full Distributed Schema Populated in {elapsed}s!\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2ti_C5eQxXAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **ðŸ” What just happened?**\n",
        "\n",
        "> We generated a **Monolithic Dataset** containing 13 related tables.\n",
        "> * **Schema Design:** We intentionally included the `state` column in the Primary Keys of all transactional tables. This is a prerequisite for Citus to perform **Co-location**.\n",
        "> * **Current State:** Right now, all data resides on the Coordinator node. It is not distributed yet."
      ],
      "metadata": {
        "id": "VEN0BMQu8VPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ—ï¸ Step 4: Execute Distribution Strategy *(Sharding)*"
      ],
      "metadata": {
        "id": "2X8wPUzy1r_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "#\n",
        "%load_ext sql\n",
        "%sql postgresql://postgres:postgres@localhost:5432/walgreens_distributed\n",
        "\n",
        "print(\"--- 1. CREATING REFERENCE TABLES (Replication) ---\")\n",
        "# Static tables are replicated to all nodes for fast local joins.\n",
        "%sql SELECT create_reference_table('Category');\n",
        "%sql SELECT create_reference_table('Payment_Method');\n",
        "%sql SELECT create_reference_table('Coupon');\n",
        "%sql SELECT create_reference_table('Product');\n",
        "\n",
        "print(\"\\n--- 2. CREATING DISTRIBUTED TABLES (Sharding by State) ---\")\n",
        "# We start with the main dimension: Branch\n",
        "%sql SELECT create_distributed_table('Branch', 'state');\n",
        "\n",
        "# Now we distribute related tables.\n",
        "# 'colocate_with' ensures data for 'TX' in Sale ends up on the same shard as 'TX' in Branch.\n",
        "print(\"... Distributing Operational Tables ...\")\n",
        "%sql SELECT create_distributed_table('Employee', 'state', colocate_with => 'Branch');\n",
        "%sql SELECT create_distributed_table('Customer', 'state', colocate_with => 'Branch');\n",
        "\n",
        "print(\"... Distributing Transactional Core ...\")\n",
        "%sql SELECT create_distributed_table('Sale', 'state', colocate_with => 'Branch');\n",
        "%sql SELECT create_distributed_table('Sale_Detail', 'state', colocate_with => 'Branch');\n",
        "\n",
        "print(\"... Distributing Invoicing & Loyalty ...\")\n",
        "%sql SELECT create_distributed_table('Invoice', 'state', colocate_with => 'Branch');\n",
        "%sql SELECT create_distributed_table('Invoice_Detail', 'state', colocate_with => 'Branch');\n",
        "%sql SELECT create_distributed_table('Redeemed_Coupon', 'state', colocate_with => 'Branch');\n",
        "%sql SELECT create_distributed_table('Points_Movement', 'state', colocate_with => 'Branch');\n",
        "\n",
        "print(\"\\nâœ… SHARDING COMPLETE! The database is now distributed.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sUFtwCYh1vSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **ðŸ” What just happened?**\n",
        "\n",
        "> This was the **Transformation Phase**. We instructed the Citus engine to reorganize the physical storage of data:\n",
        "> * **Reference Tables:** `Category`, `Product`, etc., were **replicated** (copied) to all nodes to allow fast local joins.\n",
        "> * **Distributed Tables:** `Sale`, `Invoice`, etc., were **sharded** (sliced) based on the `state` column.\n",
        "> * **Co-location:** By using `colocate_with='Branch'`, we ensured that all records belonging to 'Texas' (Sales, Customers, Invoices) are physically stored on the same shard, minimizing network latency during joins."
      ],
      "metadata": {
        "id": "_Zn6_KLy8ijG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“Š Verify the Architecture\n",
        "\n",
        "This query shows us the internal metadata of the distributed cluster."
      ],
      "metadata": {
        "id": "0Q_Aop0j6U_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT\n",
        "    table_name,\n",
        "    citus_table_type AS type,\n",
        "    distribution_column,\n",
        "    shard_count\n",
        "FROM citus_tables\n",
        "ORDER BY citus_table_type DESC, table_name;"
      ],
      "metadata": {
        "id": "WIE-UXCA6VTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **ðŸ” What just happened?**\n",
        "\n",
        "> We queried the internal Citus metadata (`citus_tables`) to audit the cluster state.\n",
        "> * **Distribution Mode:** Tables marked as `distributed` are sharded across the cluster, while `reference` tables are replicated on every node.\n",
        "> * **Shard Count (32):** You will notice a `shard_count` of **32**. This is the Citus default and an industry standard for medium-sized clusters.\n",
        "> * **Why 32?** This is a **Future-Proofing Strategy**. Even if we currently run on fewer physical nodes, having 32 \"Logical Partitions\" (virtual buckets) allows us to scale out easily in the future. When new physical nodes are added to the cluster, we simply move these existing shards to the new hardware without rewriting the data (Rebalancing)."
      ],
      "metadata": {
        "id": "6ceCn1Hj8zFW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YR59wVyj8zo2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}